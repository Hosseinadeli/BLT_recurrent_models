{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/engram/nklab/hossein/recurrent_models/BLT_models\n"
     ]
    }
   ],
   "source": [
    "data_path = '/share/data/imagenet-pytorch'\n",
    "\n",
    "import os\n",
    "os.chdir('/engram/nklab/hossein/recurrent_models/BLT_models/')\n",
    "!pwd\n",
    "\n",
    "#--wandb_p 'vggface2' --wandb_r 'blt_bl' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "| distributed init (rank 1): env://\n",
      "cuda\n",
      "100%|██████████████████████████████████████| 3890/3890 [00:05<00:00, 660.44it/s]\n",
      "100%|██████████████████████████████████████| 3890/3890 [00:05<00:00, 660.22it/s]\n",
      "100%|█████████████████████████████████████| 3890/3890 [00:02<00:00, 1943.53it/s]\n",
      "100%|█████████████████████████████████████| 3890/3890 [00:02<00:00, 1634.96it/s]\n",
      "Number of model parameters: 17200882\n",
      "blt(\n",
      "  (conv_input): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "  (non_lin_input): ReLU(inplace=True)\n",
      "  (norm_input): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "  (non_lin_0): ReLU(inplace=True)\n",
      "  (norm_0): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "  (output_0): Identity()\n",
      "  (conv_0_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_0_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_0_2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_0_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (non_lin_1): ReLU(inplace=True)\n",
      "  (norm_1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "  (output_1): Identity()\n",
      "  (conv_1_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_1_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_1_2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_1_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_1_4): Conv2d(64, 256, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))\n",
      "  (non_lin_2): ReLU(inplace=True)\n",
      "  (norm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "  (output_2): Identity()\n",
      "  (conv_2_0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_2_1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_2_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_2_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_2_5): Conv2d(128, 512, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))\n",
      "  (non_lin_3): ReLU(inplace=True)\n",
      "  (norm_3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "  (output_3): Identity()\n",
      "  (conv_3_0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_3_1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_3_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_3_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_3_5): Conv2d(128, 512, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))\n",
      "  (non_lin_4): ReLU(inplace=True)\n",
      "  (norm_4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "  (output_4): Identity()\n",
      "  (conv_4_1): ConvTranspose2d(256, 64, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), output_padding=(3, 3))\n",
      "  (conv_4_2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_4_3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_4_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_4_5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (non_lin_5): ReLU(inplace=True)\n",
      "  (norm_5): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "  (output_5): Identity()\n",
      "  (conv_5_2): ConvTranspose2d(512, 128, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), output_padding=(3, 3))\n",
      "  (conv_5_3): ConvTranspose2d(512, 128, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), output_padding=(3, 3))\n",
      "  (conv_5_4): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (conv_5_5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (read_out): Sequential(\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (flatten): Flatten()\n",
      "    (linear): Linear(in_features=512, out_features=3890, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['conv_input.weight', 'conv_input.bias', 'norm_input.weight', 'norm_input.bias', 'norm_0.weight', 'norm_0.bias', 'conv_0_0.weight', 'conv_0_0.bias', 'conv_0_1.weight', 'conv_0_1.bias', 'conv_0_2.weight', 'conv_0_2.bias', 'conv_0_3.weight', 'conv_0_3.bias', 'norm_1.weight', 'norm_1.bias', 'conv_1_0.weight', 'conv_1_0.bias', 'conv_1_1.weight', 'conv_1_1.bias', 'conv_1_2.weight', 'conv_1_2.bias', 'conv_1_3.weight', 'conv_1_3.bias', 'conv_1_4.weight', 'conv_1_4.bias', 'norm_2.weight', 'norm_2.bias', 'conv_2_0.weight', 'conv_2_0.bias', 'conv_2_1.weight', 'conv_2_1.bias', 'conv_2_2.weight', 'conv_2_2.bias', 'conv_2_3.weight', 'conv_2_3.bias', 'conv_2_4.weight', 'conv_2_4.bias', 'conv_2_5.weight', 'conv_2_5.bias', 'norm_3.weight', 'norm_3.bias', 'conv_3_0.weight', 'conv_3_0.bias', 'conv_3_1.weight', 'conv_3_1.bias', 'conv_3_2.weight', 'conv_3_2.bias', 'conv_3_3.weight', 'conv_3_3.bias', 'conv_3_4.weight', 'conv_3_4.bias', 'conv_3_5.weight', 'conv_3_5.bias', 'norm_4.weight', 'norm_4.bias', 'conv_4_1.weight', 'conv_4_1.bias', 'conv_4_2.weight', 'conv_4_2.bias', 'conv_4_3.weight', 'conv_4_3.bias', 'conv_4_4.weight', 'conv_4_4.bias', 'conv_4_5.weight', 'conv_4_5.bias', 'norm_5.weight', 'norm_5.bias', 'conv_5_2.weight', 'conv_5_2.bias', 'conv_5_3.weight', 'conv_5_3.bias', 'conv_5_4.weight', 'conv_5_4.bias', 'conv_5_5.weight', 'conv_5_5.bias', 'read_out.linear.weight', 'read_out.linear.bias']\n",
      "Start training\n",
      "[rank1]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch: [0]  [   0/5008]  eta: 1 day, 13:58:13  lr: 0.000500  loss_labels: 8.2999 (8.2999)  loss: 8.2999 (8.2999)  time: 27.2950\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/BLT_models/main.py\", line 303, in <module>\n",
      "    mp.spawn(main, args=(args.world_size, args), nprocs=args.world_size)\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 281, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 237, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 117, in join\n",
      "    ready = multiprocessing.connection.wait(\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --distributed 1 --save_model 0 --dataset 'vggface2' --num_layers 6 --model 'blt_b3lt3' --epochs 100 --lr .0005 --loss_choice 'weighted' --loss_gamma 0.2 --recurrent_steps 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --save_model 0 --dataset 'imagenet' --wandb_p 'imagenet' --wandb_r 'blt_bl'  --model 'blt_bl' --epochs 100 --lr .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 ** 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3559495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=bl_g  # The job name.\n",
    "#SBATCH --gres=gpu:3\n",
    "#SBATCH --nodelist=ax01\n",
    "#SBATCH --cpus-per-task=24\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/BLT_models/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --distributed 1 --save_model 1 --dataset 'vggface2' --wandb_p 'vggface2' --wandb_r 'bl' --num_layers 6 --model 'blt_bl' --epochs 100 --lr .0005 --loss_choice 'weighted' --loss_gamma 0 --recurrent_steps 10 --port '12384' --run 33\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --save_model 1 --dataset 'vggface2' --wandb_p 'vggface2' --wandb_r 'b_small_0.0005'  --model 'blt_b' --num_layers 6 --epochs 100 --lr .0005 --lr_drop 10 --port '12391' --run 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', choices=['weighted', 'decay'] \n",
    "                        , default='decay', type=str, \n",
    "                        help='how to apply loss to earlier readout layers')  \n",
    "    parser.add_argument("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39]",
   "language": "python",
   "name": "conda-env-.conda-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
